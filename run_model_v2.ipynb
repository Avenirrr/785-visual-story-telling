{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import time\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from beam_search import *\n",
    "from model_v2 import ModelV2\n",
    "from vist_api.vist import Story_in_Sequence\n",
    "from dataset import StoryDataset, collate_story\n",
    "from vocab import Vocabulary\n",
    "from train_test import train, test\n",
    "\n",
    "vocab_save_path = \"vocab.pt\"\n",
    "vist_annotations_dir = './vist_api/'\n",
    "images_dir = './vist_api/images/'\n",
    "sis_train = Story_in_Sequence(images_dir + \"train\", vist_annotations_dir)\n",
    "sis_val = Story_in_Sequence(images_dir+\"val\", vist_annotations_dir)\n",
    "# sis_test = Story_in_Sequence(images_dir+\"test\", vist_annotations_dir)\n",
    "\n",
    "if True:\n",
    "    corpus = []\n",
    "    for story in sis_train.Stories:\n",
    "        sent_ids = sis_train.Stories[story]['sent_ids']\n",
    "        for sent_id in sent_ids:\n",
    "            corpus.append(sis_train.Sents[sent_id]['text'])\n",
    "    vocab = Vocabulary(corpus, freq_cutoff=2)  # reads and builds\n",
    "\n",
    "    # Verifying vocabulary is the same\n",
    "    for word in vocab.w2i.keys():\n",
    "        index = vocab.w2i[word]\n",
    "        if (word != vocab.i2w[index]):\n",
    "            print('Words mismatched...')\n",
    "    # Saving vocabulary\n",
    "    with open(vocab_save_path, 'wb') as file:\n",
    "        pickle.dump(vocab, file)\n",
    "else:\n",
    "    vocab = pickle.load(open(vocab_save_path, 'rb'))\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_story_set = StoryDataset(sis_train, vocab)\n",
    "    val_story_set = StoryDataset(sis_val, vocab)\n",
    "    # test_story_set = StoryDataset(sis_test, vocab)\n",
    "\n",
    "    train_loader = DataLoader(train_story_set, shuffle=False, batch_size=BATCH_SIZE, collate_fn=collate_story,\n",
    "                              pin_memory=False)\n",
    "    # imgs of shape [BS, 5, 3, 224, 224]\n",
    "    # sents BS * 5  * MAX_LEN\n",
    "\n",
    "    model_v2 = ModelV2(vocab)\n",
    "\n",
    "    # Learning rate is the most sensitive value to set,\n",
    "    # will need to test what works well past 400 instances\n",
    "    optimizer = torch.optim.Adam(model_v2.parameters(), lr=0.05, weight_decay=1e-4)  # .001 for 400\n",
    "    isTraining = True\n",
    "\n",
    "    if isTraining:\n",
    "        train(10, model_v2, train_loader, optimizer)\n",
    "    else:\n",
    "        model_v2.load_state_dict(torch.load('./Training/7'))\n",
    "        test_loader = DataLoader(train_story_set, shuffle=False, batch_size=BATCH_SIZE, collate_fn=collate_story)\n",
    "        test(model_v2, val_story_set, vocab)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
